{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(解答)台灣+PM25+for+Student.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2 with Spark 2.0",
      "language": "python",
      "name": "python2-spark20"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/UDICatNCHU/SparkTutorial/blob/master/(%E9%A1%8C%E7%9B%AE)%E5%8F%B0%E7%81%A3+PM25+for+Student.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JjpVj8Ne_p6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZX_HQWt68dR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40147
        },
        "outputId": "418a0ddc-65a2-4128-e848-c74523d4a898"
      },
      "cell_type": "code",
      "source": [
        "# 環境初始化 (大約三至五分鐘)\n",
        "! wget -O init_env.sh https://www.dropbox.com/s/6bnwn8u2hz19s59/init_env.sh && \\\n",
        "bash init_env.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-04 07:49:34--  https://www.dropbox.com/s/6bnwn8u2hz19s59/init_env.sh\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:6022:1::a27d:4201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/6bnwn8u2hz19s59/init_env.sh [following]\n",
            "--2018-10-04 07:49:34--  https://www.dropbox.com/s/raw/6bnwn8u2hz19s59/init_env.sh\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4d9cdd213dbe895e58bd170873.dl.dropboxusercontent.com/cd/0/inline/ASLYrsO1N9HwcRmJ-8MquzgxIzpEjijskixuUrBdJkzmtcM28nalNgQsB_x-ZcH3Bwr_OrEwIYI4AtY2r_rPpUq92HpH1UOXpLhygBLF-d2ZkNn5ku93vWvF4MpXh_GSXWhp1UhXIHa-7cqbVMbwqn9IKW4W9bsWHP6SAwmcjFIqlii8fBT2fDCuc9YRmFFm3HE/file [following]\n",
            "--2018-10-04 07:49:34--  https://uc4d9cdd213dbe895e58bd170873.dl.dropboxusercontent.com/cd/0/inline/ASLYrsO1N9HwcRmJ-8MquzgxIzpEjijskixuUrBdJkzmtcM28nalNgQsB_x-ZcH3Bwr_OrEwIYI4AtY2r_rPpUq92HpH1UOXpLhygBLF-d2ZkNn5ku93vWvF4MpXh_GSXWhp1UhXIHa-7cqbVMbwqn9IKW4W9bsWHP6SAwmcjFIqlii8fBT2fDCuc9YRmFFm3HE/file\n",
            "Resolving uc4d9cdd213dbe895e58bd170873.dl.dropboxusercontent.com (uc4d9cdd213dbe895e58bd170873.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6022:6::a27d:4206\n",
            "Connecting to uc4d9cdd213dbe895e58bd170873.dl.dropboxusercontent.com (uc4d9cdd213dbe895e58bd170873.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 336 [text/plain]\n",
            "Saving to: ‘init_env.sh’\n",
            "\n",
            "init_env.sh         100%[===================>]     336  --.-KB/s    in 0s      \n",
            "\n",
            "2018-10-04 07:49:34 (37.5 MB/s) - ‘init_env.sh’ saved [336/336]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  adwaita-icon-theme at-spi2-core ca-certificates-java dconf-gsettings-backend\n",
            "  dconf-service default-jdk-headless default-jre-headless fontconfig\n",
            "  fonts-dejavu-core fonts-dejavu-extra glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas gtk-update-icon-cache\n",
            "  hicolor-icon-theme humanity-icon-theme java-common libasound2\n",
            "  libasound2-data libatk-bridge2.0-0 libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libatk1.0-0 libatk1.0-data libatspi2.0-0\n",
            "  libavahi-client3 libavahi-common-data libavahi-common3 libcairo-gobject2\n",
            "  libcairo2 libcolord2 libcroco3 libcups2 libdatrie1 libdconf1 libdrm-amdgpu1\n",
            "  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libepoxy0 libfontenc1\n",
            "  libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common libgif7\n",
            "  libgl1 libgl1-mesa-dri libgl1-mesa-glx libglx-mesa0 libglx0 libgtk-3-0\n",
            "  libgtk-3-bin libgtk-3-common libice-dev libjbig0 libjson-glib-1.0-0\n",
            "  libjson-glib-1.0-common liblcms2-2 libllvm6.0 libnspr4 libnss3\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0\n",
            "  libpcsclite1 libpixman-1-0 libproxy1v5 librest-0.7-0 librsvg2-2\n",
            "  librsvg2-common libsensors4 libsm-dev libsoup-gnome2.4-1 libsoup2.4-1\n",
            "  libthai-data libthai0 libtiff5 libwayland-cursor0 libwayland-egl1-mesa\n",
            "  libxaw7 libxcb-glx0 libxcb-render0 libxcb-shape0 libxcb-shm0 libxcomposite1\n",
            "  libxcursor1 libxdamage1 libxfixes3 libxi6 libxinerama1 libxkbcommon0 libxmu6\n",
            "  libxmuu1 libxpm4 libxrandr2 libxt-dev libxt6 libxtst6 libxv1 libxxf86dga1\n",
            "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
            "  openjdk-11-jre-headless shared-mime-info ubuntu-mono x11-utils xkb-data\n",
            "Suggested packages:\n",
            "  default-java-plugin libasound2-plugins alsa-utils colord cups-common gvfs\n",
            "  libice-doc liblcms2-utils pciutils pcscd librsvg2-bin lm-sensors libsm-doc\n",
            "  libxt-doc openjdk-11-demo openjdk-11-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  adwaita-icon-theme at-spi2-core ca-certificates-java dconf-gsettings-backend\n",
            "  dconf-service default-jdk default-jdk-headless default-jre\n",
            "  default-jre-headless fontconfig fonts-dejavu-core fonts-dejavu-extra\n",
            "  glib-networking glib-networking-common glib-networking-services\n",
            "  gsettings-desktop-schemas gtk-update-icon-cache hicolor-icon-theme\n",
            "  humanity-icon-theme java-common libasound2 libasound2-data\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libavahi-client3 libavahi-common-data\n",
            "  libavahi-common3 libcairo-gobject2 libcairo2 libcolord2 libcroco3 libcups2\n",
            "  libdatrie1 libdconf1 libdrm-amdgpu1 libdrm-intel1 libdrm-nouveau2\n",
            "  libdrm-radeon1 libepoxy0 libfontenc1 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin\n",
            "  libgdk-pixbuf2.0-common libgif7 libgl1 libgl1-mesa-dri libgl1-mesa-glx\n",
            "  libglx-mesa0 libglx0 libgtk-3-0 libgtk-3-bin libgtk-3-common libice-dev\n",
            "  libjbig0 libjson-glib-1.0-0 libjson-glib-1.0-common liblcms2-2 libllvm6.0\n",
            "  libnspr4 libnss3 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0\n",
            "  libpciaccess0 libpcsclite1 libpixman-1-0 libproxy1v5 librest-0.7-0\n",
            "  librsvg2-2 librsvg2-common libsensors4 libsm-dev libsoup-gnome2.4-1\n",
            "  libsoup2.4-1 libthai-data libthai0 libtiff5 libwayland-cursor0\n",
            "  libwayland-egl1-mesa libxaw7 libxcb-glx0 libxcb-render0 libxcb-shape0\n",
            "  libxcb-shm0 libxcomposite1 libxcursor1 libxdamage1 libxfixes3 libxi6\n",
            "  libxinerama1 libxkbcommon0 libxmu6 libxmuu1 libxpm4 libxrandr2 libxt-dev\n",
            "  libxt6 libxtst6 libxv1 libxxf86dga1 libxxf86vm1 openjdk-11-jdk\n",
            "  openjdk-11-jdk-headless openjdk-11-jre openjdk-11-jre-headless\n",
            "  shared-mime-info ubuntu-mono x11-utils xkb-data\n",
            "0 upgraded, 113 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 161 MB of archives.\n",
            "After this operation, 559 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama1 amd64 2:1.1.3-1 [7,908 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86vm1 amd64 1:1.1.4-1 [10.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 shared-mime-info amd64 1.9-2 [426 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 xkb-data all 2.23.1-1ubuntu1 [325 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmuu1 amd64 2:1.1.2-2 [9,674 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 hicolor-icon-theme all 0.17-2 [9,976 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtiff5 amd64 4.0.9-5 [152 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-common all 2.36.11-2 [4,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-0 amd64 2.36.11-2 [165 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 gtk-update-icon-cache amd64 3.22.30-1ubuntu1 [28.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-0 amd64 0.34.0-2 [229 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-render0 amd64 1.13-1 [14.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shm0 amd64 1.13-1 [5,572 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo2 amd64 1.15.10-2 [580 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcroco3 amd64 0.6.12-2 [81.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 librsvg2-2 amd64 2.40.20-2 [98.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 librsvg2-common amd64 2.40.20-2 [5,124 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 humanity-icon-theme all 0.6.15 [1,250 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 ubuntu-mono all 16.10+18.04.20180421.1-0ubuntu1 [149 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 adwaita-icon-theme all 3.28.0-1ubuntu1 [3,306 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatspi2.0-0 amd64 2.28.0-1 [59.6 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 at-spi2-core amd64 2.28.0-1 [47.9 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 java-common all 0.63ubuntu1~02 [7,032 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-common-data amd64 0.7-3.1ubuntu1.1 [22.1 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-common3 amd64 0.7-3.1ubuntu1.1 [21.7 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-client3 amd64 0.7-3.1ubuntu1.1 [25.3 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcups2 amd64 2.2.7-1ubuntu2.1 [211 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblcms2-2 amd64 2.9-1ubuntu0.1 [139 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnspr4 amd64 2:4.18-1ubuntu1 [112 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnss3 amd64 2:3.35-2ubuntu2 [1,135 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpcsclite1 amd64 1.8.23-1 [21.3 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openjdk-11-jre-headless amd64 10.0.2+13-1ubuntu0.18.04.2 [39.5 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 default-jre-headless amd64 2:1.10-63ubuntu1~02 [3,412 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ca-certificates-java all 20180516ubuntu1~18.04.1 [12.2 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdconf1 amd64 0.26.0-2ubuntu3 [33.1 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 dconf-service amd64 0.26.0-2ubuntu3 [28.4 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 dconf-gsettings-backend amd64 0.26.0-2ubuntu3 [20.0 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk-3-common all 3.22.30-1ubuntu1 [228 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk1.0-data all 2.28.1-1 [2,992 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk1.0-0 amd64 2.28.1-1 [43.9 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-bridge2.0-0 amd64 2.26.2-1 [57.3 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo-gobject2 amd64 1.15.10-2 [17.2 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcolord2 amd64 1.3.3-2build1 [107 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 libepoxy0 amd64 1.4.3-1 [181 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjson-glib-1.0-common all 1.4.2-3 [3,464 B]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjson-glib-1.0-0 amd64 1.4.2-3 [58.5 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 libproxy1v5 amd64 0.4.15-1 [49.5 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 glib-networking-common all 2.56.0-1 [3,324 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 glib-networking-services amd64 2.56.0-1 [8,488 B]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsettings-desktop-schemas all 3.28.0-1ubuntu1 [27.8 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 glib-networking amd64 2.56.0-1 [56.7 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsoup2.4-1 amd64 2.62.1-1ubuntu0.1 [292 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsoup-gnome2.4-1 amd64 2.62.1-1ubuntu0.1 [5,092 B]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 librest-0.7-0 amd64 0.8.0-2 [31.8 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwayland-cursor0 amd64 1.14.0-2 [9,976 B]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-egl1-mesa amd64 18.0.5-0ubuntu0~18.04.1 [7,148 B]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcomposite1 amd64 1:0.4.4-2 [6,988 B]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxfixes3 amd64 1:5.0.3-1 [10.8 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor1 amd64 1:1.1.15-1 [19.8 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdamage1 amd64 1:1.1.4-3 [6,934 B]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxkbcommon0 amd64 0.8.0-1 [97.6 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr2 amd64 2:1.5.1-1 [18.1 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk-3-0 amd64 3.22.30-1ubuntu1 [2,505 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-glx0 amd64 1.13-1 [22.0 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-amdgpu1 amd64 2.4.91-2 [19.0 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpciaccess0 amd64 0.14-1 [17.9 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-intel1 amd64 2.4.91-2 [59.8 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-nouveau2 amd64 2.4.91-2 [16.5 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-radeon1 amd64 2.4.91-2 [21.7 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu bionic/main amd64 libllvm6.0 amd64 1:6.0-1ubuntu2 [14.5 MB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsensors4 amd64 1:3.4.0-4 [28.8 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-dri amd64 18.0.5-0ubuntu0~18.04.1 [6,011 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx-mesa0 amd64 18.0.5-0ubuntu0~18.04.1 [132 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx0 amd64 1.0.0-2ubuntu2.2 [28.1 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1 amd64 1.0.0-2ubuntu2.2 [84.8 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-glx amd64 18.0.5-0ubuntu0~18.04.1 [3,780 B]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2-data all 1.1.3-5ubuntu0.1 [36.3 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2 amd64 1.1.3-5ubuntu0.1 [359 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgif7 amd64 5.1.4-2 [30.6 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openjdk-11-jre amd64 10.0.2+13-1ubuntu0.18.04.2 [53.2 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu bionic/main amd64 default-jre amd64 2:1.10-63ubuntu1~02 [1,092 B]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openjdk-11-jdk-headless amd64 10.0.2+13-1ubuntu0.18.04.2 [78.1 MB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu bionic/main amd64 default-jdk-headless amd64 2:1.10-63ubuntu1~02 [1,132 B]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openjdk-11-jdk amd64 10.0.2+13-1ubuntu0.18.04.2 [3,985 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu bionic/main amd64 default-jdk amd64 2:1.10-63ubuntu1~02 [1,092 B]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:99 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontenc1 amd64 1:1.1.3-1 [13.9 kB]\n",
            "Get:100 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shape0 amd64 1.13-1 [5,964 B]\n",
            "Get:105 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv1 amd64 2:1.0.11-1 [10.7 kB]\n",
            "Get:106 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:107 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:108 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:109 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-bin amd64 2.36.11-2 [7,864 B]\n",
            "Get:110 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk-3-bin amd64 3.22.30-1ubuntu1 [57.3 kB]\n",
            "Get:111 http://archive.ubuntu.com/ubuntu bionic/main amd64 libice-dev amd64 2:1.0.9-2 [46.8 kB]\n",
            "Get:112 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsm-dev amd64 2:1.2.2-1 [16.2 kB]\n",
            "Get:113 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt-dev amd64 1:1.1.5-1 [395 kB]\n",
            "Fetched 161 MB in 8s (20.1 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 21063 files and directories currently installed.)\n",
            "Preparing to unpack .../000-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libxinerama1:amd64.\n",
            "Preparing to unpack .../001-libxinerama1_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama1:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../002-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package libxxf86vm1:amd64.\n",
            "Preparing to unpack .../003-libxxf86vm1_1%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
            "Selecting previously unselected package shared-mime-info.\n",
            "Preparing to unpack .../004-shared-mime-info_1.9-2_amd64.deb ...\n",
            "Unpacking shared-mime-info (1.9-2) ...\n",
            "Selecting previously unselected package xkb-data.\n",
            "Preparing to unpack .../005-xkb-data_2.23.1-1ubuntu1_all.deb ...\n",
            "Unpacking xkb-data (2.23.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libxmuu1:amd64.\n",
            "Preparing to unpack .../006-libxmuu1_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmuu1:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package hicolor-icon-theme.\n",
            "Preparing to unpack .../007-hicolor-icon-theme_0.17-2_all.deb ...\n",
            "Unpacking hicolor-icon-theme (0.17-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../008-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../009-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-common.\n",
            "Preparing to unpack .../010-libgdk-pixbuf2.0-common_2.36.11-2_all.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-common (2.36.11-2) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-0:amd64.\n",
            "Preparing to unpack .../011-libgdk-pixbuf2.0-0_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
            "Selecting previously unselected package gtk-update-icon-cache.\n",
            "Preparing to unpack .../012-gtk-update-icon-cache_3.22.30-1ubuntu1_amd64.deb ...\n",
            "No diversion 'diversion of /usr/sbin/update-icon-caches to /usr/sbin/update-icon-caches.gtk2 by libgtk-3-bin', none removed.\n",
            "No diversion 'diversion of /usr/share/man/man8/update-icon-caches.8.gz to /usr/share/man/man8/update-icon-caches.gtk2.8.gz by libgtk-3-bin', none removed.\n",
            "Unpacking gtk-update-icon-cache (3.22.30-1ubuntu1) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../013-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../014-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../015-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../016-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libcroco3:amd64.\n",
            "Preparing to unpack .../017-libcroco3_0.6.12-2_amd64.deb ...\n",
            "Unpacking libcroco3:amd64 (0.6.12-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../018-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../019-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../020-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../021-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../022-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../023-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package librsvg2-2:amd64.\n",
            "Preparing to unpack .../024-librsvg2-2_2.40.20-2_amd64.deb ...\n",
            "Unpacking librsvg2-2:amd64 (2.40.20-2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../025-librsvg2-common_2.40.20-2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.40.20-2) ...\n",
            "Selecting previously unselected package humanity-icon-theme.\n",
            "Preparing to unpack .../026-humanity-icon-theme_0.6.15_all.deb ...\n",
            "Unpacking humanity-icon-theme (0.6.15) ...\n",
            "Selecting previously unselected package ubuntu-mono.\n",
            "Preparing to unpack .../027-ubuntu-mono_16.10+18.04.20180421.1-0ubuntu1_all.deb ...\n",
            "Unpacking ubuntu-mono (16.10+18.04.20180421.1-0ubuntu1) ...\n",
            "Selecting previously unselected package adwaita-icon-theme.\n",
            "Preparing to unpack .../028-adwaita-icon-theme_3.28.0-1ubuntu1_all.deb ...\n",
            "Unpacking adwaita-icon-theme (3.28.0-1ubuntu1) ...\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "Preparing to unpack .../029-libatspi2.0-0_2.28.0-1_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.28.0-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../030-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../031-at-spi2-core_2.28.0-1_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.28.0-1) ...\n",
            "Selecting previously unselected package java-common.\n",
            "Preparing to unpack .../032-java-common_0.63ubuntu1~02_all.deb ...\n",
            "Unpacking java-common (0.63ubuntu1~02) ...\n",
            "Selecting previously unselected package libavahi-common-data:amd64.\n",
            "Preparing to unpack .../033-libavahi-common-data_0.7-3.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libavahi-common-data:amd64 (0.7-3.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libavahi-common3:amd64.\n",
            "Preparing to unpack .../034-libavahi-common3_0.7-3.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libavahi-common3:amd64 (0.7-3.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libavahi-client3:amd64.\n",
            "Preparing to unpack .../035-libavahi-client3_0.7-3.1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libavahi-client3:amd64 (0.7-3.1ubuntu1.1) ...\n",
            "Selecting previously unselected package libcups2:amd64.\n",
            "Preparing to unpack .../036-libcups2_2.2.7-1ubuntu2.1_amd64.deb ...\n",
            "Unpacking libcups2:amd64 (2.2.7-1ubuntu2.1) ...\n",
            "Selecting previously unselected package liblcms2-2:amd64.\n",
            "Preparing to unpack .../037-liblcms2-2_2.9-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblcms2-2:amd64 (2.9-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libnspr4:amd64.\n",
            "Preparing to unpack .../038-libnspr4_2%3a4.18-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnspr4:amd64 (2:4.18-1ubuntu1) ...\n",
            "Selecting previously unselected package libnss3:amd64.\n",
            "Preparing to unpack .../039-libnss3_2%3a3.35-2ubuntu2_amd64.deb ...\n",
            "Unpacking libnss3:amd64 (2:3.35-2ubuntu2) ...\n",
            "Selecting previously unselected package libpcsclite1:amd64.\n",
            "Preparing to unpack .../040-libpcsclite1_1.8.23-1_amd64.deb ...\n",
            "Unpacking libpcsclite1:amd64 (1.8.23-1) ...\n",
            "Selecting previously unselected package libxi6:amd64.\n",
            "Preparing to unpack .../041-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
            "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
            "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
            "Preparing to unpack .../042-openjdk-11-jre-headless_10.0.2+13-1ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking openjdk-11-jre-headless:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package default-jre-headless.\n",
            "Preparing to unpack .../043-default-jre-headless_2%3a1.10-63ubuntu1~02_amd64.deb ...\n",
            "Unpacking default-jre-headless (2:1.10-63ubuntu1~02) ...\n",
            "Selecting previously unselected package ca-certificates-java.\n",
            "Preparing to unpack .../044-ca-certificates-java_20180516ubuntu1~18.04.1_all.deb ...\n",
            "Unpacking ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libdconf1:amd64.\n",
            "Preparing to unpack .../045-libdconf1_0.26.0-2ubuntu3_amd64.deb ...\n",
            "Unpacking libdconf1:amd64 (0.26.0-2ubuntu3) ...\n",
            "Selecting previously unselected package dconf-service.\n",
            "Preparing to unpack .../046-dconf-service_0.26.0-2ubuntu3_amd64.deb ...\n",
            "Unpacking dconf-service (0.26.0-2ubuntu3) ...\n",
            "Selecting previously unselected package dconf-gsettings-backend:amd64.\n",
            "Preparing to unpack .../047-dconf-gsettings-backend_0.26.0-2ubuntu3_amd64.deb ...\n",
            "Unpacking dconf-gsettings-backend:amd64 (0.26.0-2ubuntu3) ...\n",
            "Selecting previously unselected package libgtk-3-common.\n",
            "Preparing to unpack .../048-libgtk-3-common_3.22.30-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk-3-common (3.22.30-1ubuntu1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../049-libatk1.0-data_2.28.1-1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.28.1-1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../050-libatk1.0-0_2.28.1-1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../051-libatk-bridge2.0-0_2.26.2-1_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.26.2-1) ...\n",
            "Selecting previously unselected package libcairo-gobject2:amd64.\n",
            "Preparing to unpack .../052-libcairo-gobject2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo-gobject2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libcolord2:amd64.\n",
            "Preparing to unpack .../053-libcolord2_1.3.3-2build1_amd64.deb ...\n",
            "Unpacking libcolord2:amd64 (1.3.3-2build1) ...\n",
            "Selecting previously unselected package libepoxy0:amd64.\n",
            "Preparing to unpack .../054-libepoxy0_1.4.3-1_amd64.deb ...\n",
            "Unpacking libepoxy0:amd64 (1.4.3-1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../055-libjson-glib-1.0-common_1.4.2-3_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.4.2-3) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../056-libjson-glib-1.0-0_1.4.2-3_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.4.2-3) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../057-libproxy1v5_0.4.15-1_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.15-1) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../058-glib-networking-common_2.56.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.56.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../059-glib-networking-services_2.56.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.56.0-1) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../060-gsettings-desktop-schemas_3.28.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (3.28.0-1ubuntu1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../061-glib-networking_2.56.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.56.0-1) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../062-libsoup2.4-1_2.62.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.62.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libsoup-gnome2.4-1:amd64.\n",
            "Preparing to unpack .../063-libsoup-gnome2.4-1_2.62.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsoup-gnome2.4-1:amd64 (2.62.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package librest-0.7-0:amd64.\n",
            "Preparing to unpack .../064-librest-0.7-0_0.8.0-2_amd64.deb ...\n",
            "Unpacking librest-0.7-0:amd64 (0.8.0-2) ...\n",
            "Selecting previously unselected package libwayland-cursor0:amd64.\n",
            "Preparing to unpack .../065-libwayland-cursor0_1.14.0-2_amd64.deb ...\n",
            "Unpacking libwayland-cursor0:amd64 (1.14.0-2) ...\n",
            "Selecting previously unselected package libwayland-egl1-mesa:amd64.\n",
            "Preparing to unpack .../066-libwayland-egl1-mesa_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libwayland-egl1-mesa:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../067-libxcomposite1_1%3a0.4.4-2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.4-2) ...\n",
            "Selecting previously unselected package libxfixes3:amd64.\n",
            "Preparing to unpack .../068-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
            "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
            "Selecting previously unselected package libxcursor1:amd64.\n",
            "Preparing to unpack .../069-libxcursor1_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor1:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package libxdamage1:amd64.\n",
            "Preparing to unpack .../070-libxdamage1_1%3a1.1.4-3_amd64.deb ...\n",
            "Unpacking libxdamage1:amd64 (1:1.1.4-3) ...\n",
            "Selecting previously unselected package libxkbcommon0:amd64.\n",
            "Preparing to unpack .../071-libxkbcommon0_0.8.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon0:amd64 (0.8.0-1) ...\n",
            "Selecting previously unselected package libxrandr2:amd64.\n",
            "Preparing to unpack .../072-libxrandr2_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr2:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libgtk-3-0:amd64.\n",
            "Preparing to unpack .../073-libgtk-3-0_3.22.30-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk-3-0:amd64 (3.22.30-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-glx0:amd64.\n",
            "Preparing to unpack .../074-libxcb-glx0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-glx0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
            "Preparing to unpack .../075-libdrm-amdgpu1_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-amdgpu1:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libpciaccess0:amd64.\n",
            "Preparing to unpack .../076-libpciaccess0_0.14-1_amd64.deb ...\n",
            "Unpacking libpciaccess0:amd64 (0.14-1) ...\n",
            "Selecting previously unselected package libdrm-intel1:amd64.\n",
            "Preparing to unpack .../077-libdrm-intel1_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-intel1:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
            "Preparing to unpack .../078-libdrm-nouveau2_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-nouveau2:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libdrm-radeon1:amd64.\n",
            "Preparing to unpack .../079-libdrm-radeon1_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-radeon1:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libllvm6.0:amd64.\n",
            "Preparing to unpack .../080-libllvm6.0_1%3a6.0-1ubuntu2_amd64.deb ...\n",
            "Unpacking libllvm6.0:amd64 (1:6.0-1ubuntu2) ...\n",
            "Selecting previously unselected package libsensors4:amd64.\n",
            "Preparing to unpack .../081-libsensors4_1%3a3.4.0-4_amd64.deb ...\n",
            "Unpacking libsensors4:amd64 (1:3.4.0-4) ...\n",
            "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
            "Preparing to unpack .../082-libgl1-mesa-dri_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dri:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libglx-mesa0:amd64.\n",
            "Preparing to unpack .../083-libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libglx-mesa0:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libglx0:amd64.\n",
            "Preparing to unpack .../084-libglx0_1.0.0-2ubuntu2.2_amd64.deb ...\n",
            "Unpacking libglx0:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Selecting previously unselected package libgl1:amd64.\n",
            "Preparing to unpack .../085-libgl1_1.0.0-2ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgl1:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../086-libgl1-mesa-glx_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libasound2-data.\n",
            "Preparing to unpack .../087-libasound2-data_1.1.3-5ubuntu0.1_all.deb ...\n",
            "Unpacking libasound2-data (1.1.3-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libasound2:amd64.\n",
            "Preparing to unpack .../088-libasound2_1.1.3-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking libasound2:amd64 (1.1.3-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libgif7:amd64.\n",
            "Preparing to unpack .../089-libgif7_5.1.4-2_amd64.deb ...\n",
            "Unpacking libgif7:amd64 (5.1.4-2) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../090-openjdk-11-jre_10.0.2+13-1ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package default-jre.\n",
            "Preparing to unpack .../091-default-jre_2%3a1.10-63ubuntu1~02_amd64.deb ...\n",
            "Unpacking default-jre (2:1.10-63ubuntu1~02) ...\n",
            "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
            "Preparing to unpack .../092-openjdk-11-jdk-headless_10.0.2+13-1ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk-headless:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package default-jdk-headless.\n",
            "Preparing to unpack .../093-default-jdk-headless_2%3a1.10-63ubuntu1~02_amd64.deb ...\n",
            "Unpacking default-jdk-headless (2:1.10-63ubuntu1~02) ...\n",
            "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
            "Preparing to unpack .../094-openjdk-11-jdk_10.0.2+13-1ubuntu0.18.04.2_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package default-jdk.\n",
            "Preparing to unpack .../095-default-jdk_2%3a1.10-63ubuntu1~02_amd64.deb ...\n",
            "Unpacking default-jdk (2:1.10-63ubuntu1~02) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../096-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../097-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../098-libfontenc1_1%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.3-1) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../099-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../100-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../101-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../102-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package libxcb-shape0:amd64.\n",
            "Preparing to unpack .../103-libxcb-shape0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shape0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxv1:amd64.\n",
            "Preparing to unpack .../104-libxv1_2%3a1.0.11-1_amd64.deb ...\n",
            "Unpacking libxv1:amd64 (2:1.0.11-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../105-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../106-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../107-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-bin.\n",
            "Preparing to unpack .../108-libgdk-pixbuf2.0-bin_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-bin (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk-3-bin.\n",
            "Preparing to unpack .../109-libgtk-3-bin_3.22.30-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk-3-bin (3.22.30-1ubuntu1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../110-libice-dev_2%3a1.0.9-2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.9-2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../111-libsm-dev_2%3a1.2.2-1_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.2-1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../112-libxt-dev_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.1.5-1) ...\n",
            "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
            "Setting up libxinerama1:amd64 (2:1.1.3-1) ...\n",
            "Setting up libxcb-glx0:amd64 (1.13-1) ...\n",
            "Setting up libjson-glib-1.0-common (1.4.2-3) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up glib-networking-common (2.56.0-1) ...\n",
            "Setting up libxdamage1:amd64 (1:1.1.4-3) ...\n",
            "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up libdrm-amdgpu1:amd64 (2.4.91-2) ...\n",
            "Setting up libllvm6.0:amd64 (1:6.0-1ubuntu2) ...\n",
            "Setting up liblcms2-2:amd64 (2.9-1ubuntu0.1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libpcsclite1:amd64 (1.8.23-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.28.0-1) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.56.2-0ubuntu0.18.04.2) ...\n",
            "Setting up libasound2-data (1.1.3-5ubuntu0.1) ...\n",
            "Setting up xkb-data (2.23.1-1ubuntu1) ...\n",
            "Setting up libproxy1v5:amd64 (0.4.15-1) ...\n",
            "Setting up java-common (0.63ubuntu1~02) ...\n",
            "Setting up libgdk-pixbuf2.0-common (2.36.11-2) ...\n",
            "Setting up glib-networking-services (2.56.0-1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libgif7:amd64 (5.1.4-2) ...\n",
            "Setting up libnspr4:amd64 (2:4.18-1ubuntu1) ...\n",
            "Setting up libxmuu1:amd64 (2:1.1.2-2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up libasound2:amd64 (1.1.3-5ubuntu0.1) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.4.2-3) ...\n",
            "Setting up libcroco3:amd64 (0.6.12-2) ...\n",
            "Setting up libatk1.0-data (2.28.1-1) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Setting up libxcursor1:amd64 (1:1.1.15-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libepoxy0:amd64 (1.4.3-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.9-2) ...\n",
            "Setting up libatk1.0-0:amd64 (2.28.1-1) ...\n",
            "Setting up libwayland-egl1-mesa:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.26.2-1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.3-1) ...\n",
            "Setting up libdconf1:amd64 (0.26.0-2ubuntu3) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.4-2) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Setting up libxcb-shape0:amd64 (1.13-1) ...\n",
            "Setting up libpciaccess0:amd64 (0.14-1) ...\n",
            "Setting up libxv1:amd64 (2:1.0.11-1) ...\n",
            "Setting up libsensors4:amd64 (1:3.4.0-4) ...\n",
            "Setting up shared-mime-info (1.9-2) ...\n",
            "Setting up libxkbcommon0:amd64 (0.8.0-1) ...\n",
            "Setting up libdrm-radeon1:amd64 (2.4.91-2) ...\n",
            "Setting up libcolord2:amd64 (1.3.3-2build1) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
            "Setting up libdrm-nouveau2:amd64 (2.4.91-2) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Processing triggers for ca-certificates (20180409) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "done.\n",
            "Setting up hicolor-icon-theme (0.17-2) ...\n",
            "Setting up libwayland-cursor0:amd64 (1.14.0-2) ...\n",
            "Setting up libxrandr2:amd64 (2:1.5.1-1) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libavahi-common-data:amd64 (0.7-3.1ubuntu1.1) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.2-1) ...\n",
            "Setting up dconf-service (0.26.0-2ubuntu3) ...\n",
            "Setting up at-spi2-core (2.28.0-1) ...\n",
            "Setting up libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
            "Setting up libcairo-gobject2:amd64 (1.15.10-2) ...\n",
            "Setting up libgdk-pixbuf2.0-bin (2.36.11-2) ...\n",
            "Setting up libnss3:amd64 (2:3.35-2ubuntu2) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libdrm-intel1:amd64 (2.4.91-2) ...\n",
            "Setting up gtk-update-icon-cache (3.22.30-1ubuntu1) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libavahi-common3:amd64 (0.7-3.1ubuntu1.1) ...\n",
            "Setting up dconf-gsettings-backend:amd64 (0.26.0-2ubuntu3) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libxt-dev:amd64 (1:1.1.5-1) ...\n",
            "Setting up gsettings-desktop-schemas (3.28.0-1ubuntu1) ...\n",
            "Setting up libgtk-3-common (3.22.30-1ubuntu1) ...\n",
            "Setting up libgl1-mesa-dri:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up glib-networking:amd64 (2.56.0-1) ...\n",
            "Setting up libavahi-client3:amd64 (0.7-3.1ubuntu1.1) ...\n",
            "Setting up libglx-mesa0:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libcups2:amd64 (2.2.7-1ubuntu2.1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.62.1-1ubuntu0.1) ...\n",
            "Setting up libsoup-gnome2.4-1:amd64 (2.62.1-1ubuntu0.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up librest-0.7-0:amd64 (0.8.0-2) ...\n",
            "Setting up libglx0:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Setting up librsvg2-2:amd64 (2.40.20-2) ...\n",
            "Setting up librsvg2-common:amd64 (2.40.20-2) ...\n",
            "Setting up libgl1:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up adwaita-icon-theme (3.28.0-1ubuntu1) ...\n",
            "update-alternatives: using /usr/share/icons/Adwaita/cursor.theme to provide /usr/share/icons/default/index.theme (x-cursor-theme) in auto mode\n",
            "Setting up openjdk-11-jre-headless:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-11-jdk-headless:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "Setting up humanity-icon-theme (0.6.15) ...\n",
            "Setting up libgtk-3-0:amd64 (3.22.30-1ubuntu1) ...\n",
            "Setting up libgtk-3-bin (3.22.30-1ubuntu1) ...\n",
            "Setting up default-jre-headless (2:1.10-63ubuntu1~02) ...\n",
            "Setting up default-jdk-headless (2:1.10-63ubuntu1~02) ...\n",
            "Setting up openjdk-11-jre:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "Setting up ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
            "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
            "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:TrustCor_RootCert_CA-1.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
            "Adding debian:EE_Certification_Centre_Root_CA.pem\n",
            "Adding debian:AffirmTrust_Premium.pem\n",
            "Adding debian:CFCA_EV_ROOT.pem\n",
            "Adding debian:GeoTrust_Primary_Certification_Authority.pem\n",
            "Adding debian:GeoTrust_Primary_Certification_Authority_-_G3.pem\n",
            "Adding debian:Baltimore_CyberTrust_Root.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
            "Adding debian:ACCVRAIZ1.pem\n",
            "Adding debian:LuxTrust_Global_Root_2.pem\n",
            "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
            "Adding debian:OpenTrust_Root_CA_G3.pem\n",
            "Adding debian:Certigna.pem\n",
            "Adding debian:Security_Communication_RootCA2.pem\n",
            "Adding debian:QuoVadis_Root_CA_2.pem\n",
            "Adding debian:SecureTrust_CA.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
            "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
            "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
            "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
            "Adding debian:GeoTrust_Global_CA.pem\n",
            "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
            "Adding debian:AffirmTrust_Premium_ECC.pem\n",
            "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
            "Adding debian:thawte_Primary_Root_CA_-_G2.pem\n",
            "Adding debian:Certplus_Root_CA_G2.pem\n",
            "Adding debian:certSIGN_ROOT_CA.pem\n",
            "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
            "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
            "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
            "Adding debian:Sonera_Class_2_Root_CA.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
            "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
            "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
            "Adding debian:Cybertrust_Global_Root.pem\n",
            "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
            "Adding debian:CA_Disig_Root_R2.pem\n",
            "Adding debian:QuoVadis_Root_CA.pem\n",
            "Adding debian:Security_Communication_Root_CA.pem\n",
            "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
            "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
            "Adding debian:TWCA_Root_Certification_Authority.pem\n",
            "Adding debian:Atos_TrustedRoot_2011.pem\n",
            "Adding debian:Secure_Global_CA.pem\n",
            "Adding debian:DigiCert_Global_Root_G3.pem\n",
            "Adding debian:Certinomis_-_Root_CA.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
            "Adding debian:Amazon_Root_CA_1.pem\n",
            "Adding debian:GeoTrust_Universal_CA.pem\n",
            "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
            "Adding debian:TrustCor_ECA-1.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
            "Adding debian:Go_Daddy_Class_2_CA.pem\n",
            "Adding debian:Staat_der_Nederlanden_Root_CA_-_G2.pem\n",
            "Adding debian:Certum_Trusted_Network_CA.pem\n",
            "Adding debian:GlobalSign_Root_CA.pem\n",
            "Adding debian:EC-ACC.pem\n",
            "Adding debian:TrustCor_RootCert_CA-2.pem\n",
            "Adding debian:Buypass_Class_2_Root_CA.pem\n",
            "Adding debian:Starfield_Class_2_CA.pem\n",
            "Adding debian:Deutsche_Telekom_Root_CA_2.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
            "Adding debian:AffirmTrust_Networking.pem\n",
            "Adding debian:Actalis_Authentication_Root_CA.pem\n",
            "Adding debian:thawte_Primary_Root_CA_-_G3.pem\n",
            "Adding debian:ePKI_Root_Certification_Authority.pem\n",
            "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
            "Adding debian:TÜRKTRUST_Elektronik_Sertifika_Hizmet_Sağlayıcısı_H5.pem\n",
            "Adding debian:TWCA_Global_Root_CA.pem\n",
            "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
            "Adding debian:Comodo_AAA_Services_root.pem\n",
            "Adding debian:ISRG_Root_X1.pem\n",
            "Adding debian:SecureSign_RootCA11.pem\n",
            "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G4.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority.pem\n",
            "Adding debian:Certplus_Root_CA_G1.pem\n",
            "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
            "Adding debian:QuoVadis_Root_CA_3.pem\n",
            "Adding debian:Amazon_Root_CA_3.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GA_CA.pem\n",
            "Adding debian:AffirmTrust_Commercial.pem\n",
            "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
            "Adding debian:Buypass_Class_3_Root_CA.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
            "Adding debian:thawte_Primary_Root_CA.pem\n",
            "Adding debian:GeoTrust_Universal_CA_2.pem\n",
            "Adding debian:DigiCert_Global_Root_G2.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
            "Adding debian:VeriSign_Universal_Root_Certification_Authority.pem\n",
            "Adding debian:Amazon_Root_CA_4.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
            "Adding debian:Taiwan_GRCA.pem\n",
            "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
            "Adding debian:Trustis_FPS_Root_CA.pem\n",
            "Adding debian:OpenTrust_Root_CA_G2.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
            "Adding debian:Visa_eCommerce_Root.pem\n",
            "Adding debian:XRamp_Global_CA_Root.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
            "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
            "Adding debian:AddTrust_External_Root.pem\n",
            "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
            "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
            "Adding debian:COMODO_Certification_Authority.pem\n",
            "Adding debian:Certplus_Class_2_Primary_CA.pem\n",
            "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
            "Adding debian:E-Tugra_Certification_Authority.pem\n",
            "Adding debian:Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem\n",
            "Adding debian:OpenTrust_Root_CA_G1.pem\n",
            "Adding debian:Izenpe.com.pem\n",
            "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Amazon_Root_CA_2.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
            "Adding debian:DST_Root_CA_X3.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
            "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G5.pem\n",
            "Adding debian:GeoTrust_Primary_Certification_Authority_-_G2.pem\n",
            "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
            "Adding debian:SZAFIR_ROOT_CA2.pem\n",
            "Adding debian:DigiCert_Global_Root_CA.pem\n",
            "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
            "done.\n",
            "Setting up ubuntu-mono (16.10+18.04.20180421.1-0ubuntu1) ...\n",
            "Setting up default-jre (2:1.10-63ubuntu1~02) ...\n",
            "Setting up openjdk-11-jdk:amd64 (10.0.2+13-1ubuntu0.18.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up default-jdk (2:1.10-63ubuntu1~02) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
            "Processing triggers for ca-certificates (20180409) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n",
            "--2018-10-04 07:50:46--  https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz\n",
            "Resolving d3kbcqa49mib13.cloudfront.net (d3kbcqa49mib13.cloudfront.net)... 52.85.39.106, 52.85.39.243, 52.85.39.183, ...\n",
            "Connecting to d3kbcqa49mib13.cloudfront.net (d3kbcqa49mib13.cloudfront.net)|52.85.39.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203728858 (194M) [application/x-tar]\n",
            "Saving to: ‘spark-2.2.0-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.2.0-bin-had 100%[===================>] 194.29M  28.6MB/s    in 7.3s    \n",
            "\n",
            "2018-10-04 07:50:54 (26.4 MB/s) - ‘spark-2.2.0-bin-hadoop2.7.tgz’ saved [203728858/203728858]\n",
            "\n",
            "spark-2.2.0-bin-hadoop2.7/\n",
            "spark-2.2.0-bin-hadoop2.7/NOTICE\n",
            "spark-2.2.0-bin-hadoop2.7/jars/\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-common-1.8.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-net-2.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/antlr-runtime-3.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-hadoop-1.8.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-sketch_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/stream-2.7.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/kryo-shaded-3.0.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/metrics-jvm-3.1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/RoaringBitmap-0.5.11.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jets3t-0.9.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-compress-1.4.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-beanutils-1.7.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-format-2.3.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/avro-1.7.7.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jline-2.12.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/metrics-core-3.1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/java-xmlbuilder-1.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/xbean-asm5-shaded-4.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-sql_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/json4s-jackson_2.11-3.2.11.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/json4s-ast_2.11-3.2.11.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-common-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-graphx_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-network-common_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/pmml-schema-1.2.15.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/joda-time-2.9.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/curator-recipes-2.6.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-server-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/httpclient-4.5.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/snappy-0.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-tags_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-databind-2.6.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/curator-client-2.6.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/paranamer-2.6.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/json4s-core_2.11-3.2.11.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jsr305-1.3.9.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-repl_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/pyrolite-4.13.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/scala-xml_2.11-1.0.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jtransforms-2.4.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/httpcore-4.4.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-yarn_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-hive_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/netty-all-4.0.43.Final.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/curator-framework-2.6.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/avro-ipc-1.7.7.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/mesos-1.0.0-shaded-protobuf.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-annotations-2.6.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-jackson-1.8.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.6.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/janino-3.0.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/antlr4-runtime-4.5.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-lang3-3.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/bcprov-jdk15on-1.51.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-launcher_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/metrics-graphite-3.1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/lz4-1.3.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-mesos_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/antlr-2.7.7.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/mx4j-3.0.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-beanutils-core-1.8.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/libthrift-0.9.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-encoding-1.8.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-mllib_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/mail-1.4.7.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/metrics-json-3.1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/scalap-2.11.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/zookeeper-3.4.6.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/py4j-0.10.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/pmml-model-1.2.15.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/parquet-column-1.8.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/breeze_2.11-0.13.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/chill-java-0.8.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/avro-mapred-1.7.7-hadoop2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/snappy-java-1.1.2.6.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/base64-2.3.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-compiler-3.0.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/objenesis-2.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jersey-client-2.22.2.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/univocity-parsers-2.2.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.0.4.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/jackson-core-2.6.5.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/xz-1.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/scala-reflect-2.11.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/scala-compiler-2.11.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-core_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/netty-3.9.9.Final.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/spark-streaming_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/chill_2.11-0.8.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/scala-library-2.11.8.jar\n",
            "spark-2.2.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar\n",
            "spark-2.2.0-bin-hadoop2.7/python/\n",
            "spark-2.2.0-bin-hadoop2.7/python/run-tests.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-2.2.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pylintrc\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.ml.rst\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/conf.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/_templates/\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/_templates/layout.html\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.rst\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/epytext.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/index.rst\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/_static/\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/_static/pyspark.js\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/_static/pyspark.css\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.sql.rst\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n",
            "spark-2.2.0-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-2.2.0-bin-hadoop2.7/python/.gitignore\n",
            "spark-2.2.0-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/tests.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/tests.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/python/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/python/pyspark/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/tests.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/heapq3.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/cloudpickle.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/tests.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/flume.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/kafka.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/tests.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/setup.cfg\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/run-tests\n",
            "spark-2.2.0-bin-hadoop2.7/python/dist/\n",
            "spark-2.2.0-bin-hadoop2.7/python/setup.py\n",
            "spark-2.2.0-bin-hadoop2.7/python/lib/\n",
            "spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip\n",
            "spark-2.2.0-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-2.2.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-2.2.0-bin-hadoop2.7/python/README.md\n",
            "spark-2.2.0-bin-hadoop2.7/RELEASE\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-shuffle-service.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-shuffle-service.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-2.2.0-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-2.2.0-bin-hadoop2.7/examples/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/kafka_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/direct_kafka_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/flume_wordcount.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaFlumeEventCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaKafkaWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/FlumePollingEventCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/FlumeEventCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/KafkaWordCount.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-2.2.0-bin-hadoop2.7/examples/jars/\n",
            "spark-2.2.0-bin-hadoop2.7/examples/jars/scopt_2.11-3.3.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.2.0.jar\n",
            "spark-2.2.0-bin-hadoop2.7/data/\n",
            "spark-2.2.0-bin-hadoop2.7/data/graphx/\n",
            "spark-2.2.0-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/streaming/\n",
            "spark-2.2.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/als/\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-2.2.0-bin-hadoop2.7/R/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/groupBy.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/covar_pop.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sampleBy.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sql.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/year.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tan.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GBTRegressionModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/last_day.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sign.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hint.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/randn.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/orderBy.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/otherwise.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/AFTSurvivalRegressionModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hashCode.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/bin.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dim.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.svmLinear.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/minute.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createExternalTable-deprecated.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/distinct.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.conf.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/print.jobj.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/md5.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cbrt.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.ml.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dapplyCollect.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/acos.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tables.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/NaiveBayesModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sum.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/structType.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hex.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/isLocal.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.jdbc.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/from_utc_timestamp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tableNames.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createDataFrame.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/isStreaming.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/toJSON.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.getSparkFiles.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/except.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/LDAModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/months_between.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark_partition_id.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.parquet.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sumDistinct.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/awaitTermination.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/BisectingKMeansModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sha2.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/abs.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/date_format.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/withColumn.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dayofyear.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sort_array.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/storageLevel.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setCurrentDatabase.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ceil.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/floor.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/stddev_pop.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sd.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/print.structType.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.survreg.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/predict.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/count.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unhex.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/mean.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/instr.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/from_unixtime.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/saveAsTable.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ltrim.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkRHive.init-deprecated.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.parquet.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/match.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/is.nan.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.ml.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lag.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.json.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unpersist.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/corr.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.callJStatic.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rint.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/LinearSVCModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.gbt.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/RandomForestClassificationModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/persist.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/var_pop.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/selectExpr.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/crc32.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/expr.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.callJMethod.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/with.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/generateAliasesForIntersectedCols.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GeneralizedLinearRegressionModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/IsotonicRegressionModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setLogLevel.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/shiftRightUnsigned.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/base64.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/array_contains.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/expm1.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.orc.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.version.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/insertInto.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/SparkDataFrame.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/merge.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dayofmonth.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listDatabases.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/summarize.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/format_number.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/from_json.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dropDuplicates.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cache.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.text.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/approxCountDistinct.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkRSQL.init-deprecated.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/LogisticRegressionModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/stddev_samp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/pivot.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/showDF.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/between.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/struct.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/subset.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/posexplode.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lit.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/shiftLeft.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/glm.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hypot.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/recoverPartitions.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.session.stop.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/translate.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/drop.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GBTClassificationModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/shiftRight.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/regexp_replace.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/randomSplit.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/length.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rowsBetween.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.jdbc.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/schema.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/toRadians.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/filter.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/bround.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createOrReplaceTempView.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cancelJobGroup.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/second.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/upper.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/head.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/limit.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/concat_ws.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/when.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/FPGrowthModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/install.spark.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.newJObject.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dropTempView.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unbase64.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/soundex.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/structField.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.addFile.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.bisectingKmeans.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cacheTable.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cosh.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.mlp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ntile.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/atan2.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.kstest.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dtypes.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/reverse.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sinh.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.lda.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createTable.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/negate.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/asin.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hash.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rank.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/toDegrees.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/columns.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/columnfunctions.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/substring_index.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_timestamp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.naiveBayes.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/atan.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.isoreg.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/factorial.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/countDistinct.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/quarter.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setCheckpointDir.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/least.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.text.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/windowOrderBy.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dapply.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/coalesce.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/refreshByPath.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cume_dist.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dense_rank.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/freqItems.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/getNumPartitions.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/KMeansModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.session.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/arrange.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.stream.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/encode.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.glm.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/isActive.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/crossJoin.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rpad.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/uncacheTable.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/size.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/conv.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log10.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/collect.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.stream.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/format_string.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/windowPartitionBy.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/union.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/stopQuery.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dropTempTable-deprecated.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/endsWith.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/startsWith.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/nanvl.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/mutate.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/explain.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cov.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/var_samp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log2.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/registerTempTable-deprecated.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lastProgress.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/attach.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/min.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ncol.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/month.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/window.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/partitionBy.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/percent_rank.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listFunctions.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_utc_timestamp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/crosstab.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/take.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/exp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_json.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/column.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ifelse.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GaussianMixtureModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.logit.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/show.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setJobGroup.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/KSTest-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/clearJobGroup.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/last.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/printSchema.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rename.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rbind.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/over.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/MultilayerPerceptronClassificationModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/coltypes.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/datediff.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lead.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/summary.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/WindowSpec.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unix_timestamp.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tanh.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listColumns.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_date.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.uiWebUrl.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/max.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/var.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/print.structField.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.als.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/alias.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sha1.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/status.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.orc.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/currentDatabase.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.df.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/round.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.init-deprecated.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/refreshTable.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/nrow.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/pmod.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/intersect.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rtrim.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/substr.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/levenshtein.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/monotonically_increasing_id.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/checkpoint.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/decode.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.lapply.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.json.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/RandomForestRegressionModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/trim.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/select.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/regexp_extract.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/as.data.frame.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rangeBetween.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/queryName.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sample.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lower.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/repartition.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/concat.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cast.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/date_add.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.fpGrowth.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hour.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/initcap.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/explode.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/add_months.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/bitwiseNOT.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/approxQuantile.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/kurtosis.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/greatest.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/first.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.df.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rand.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/next_day.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/clearCache.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/nafunctions.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/row_number.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lpad.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/skewness.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/gapplyCollect.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/locate.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/avg.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sqrt.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cos.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log1p.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/str.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/StreamingQuery.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ALSModel-class.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ascii.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listTables.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sin.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/histogram.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/weekofyear.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GroupedData.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/fitted.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/date_sub.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tableToDF.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.getSparkFilesRootDirectory.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/join.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/gapply.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.randomForest.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.kmeans.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.gaussianMixture.html\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-scalacheck.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-Mockito.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-junit-interface.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-boto.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-SnapTree.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jpmml-model.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jbcrypt.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-postgresql.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-DPark.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-2.2.0-bin-hadoop2.7/conf/\n",
            "spark-2.2.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-2.2.0-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-2.2.0-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-2.2.0-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-2.2.0-bin-hadoop2.7/conf/docker.properties.template\n",
            "spark-2.2.0-bin-hadoop2.7/conf/slaves.template\n",
            "spark-2.2.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-2.2.0-bin-hadoop2.7/LICENSE\n",
            "spark-2.2.0-bin-hadoop2.7/bin/\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-shell\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/pyspark\n",
            "spark-2.2.0-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-class\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-submit\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-sql\n",
            "spark-2.2.0-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-2.2.0-bin-hadoop2.7/bin/run-example\n",
            "spark-2.2.0-bin-hadoop2.7/bin/beeline\n",
            "spark-2.2.0-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/sparkR\n",
            "spark-2.2.0-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-2.2.0-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-2.2.0-bin-hadoop2.7/yarn/\n",
            "spark-2.2.0-bin-hadoop2.7/yarn/spark-2.2.0-yarn-shuffle.jar\n",
            "spark-2.2.0-bin-hadoop2.7/README.md\n",
            "環境初始化完畢\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ky97pnWo7EBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "os.environ['SPARK_HOME'] = \"/usr/local/spark\"\n",
        "os.environ['PYSPARK_PYTHON'] = \"/usr/bin/python\"\n",
        "sys.path.append(\"/usr/local/spark/python/\")\n",
        "sys.path.append(\"/usr/local/spark/python/lib/pyspark.zip\")\n",
        "sys.path.append(\"/usr/local/spark/python/lib/py4j-0.10.4-src.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I1kaE7kK7PRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "sc =SparkContext()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltQpoNZY6bv6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 利用Spark 分析台灣2015 PM2.5資料集"
      ]
    },
    {
      "metadata": {
        "id": "zbWZ0dIo6bv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"load_data\"></a>\n",
        "## 上傳台灣2015一整年空氣監測資料 "
      ]
    },
    {
      "metadata": {
        "id": "C1qgJDsb6bv8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟1: 將2015空氣監控資料，上傳至colab"
      ]
    },
    {
      "metadata": {
        "id": "SVXc7N-P6bv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "f=urllib.urlretrieve(\"https://www.dropbox.com/s/zkn3ba7pitv83el/pm2.5Taiwan.csv?dl=1\",\"pm25.csv\")\n",
        "data_file = \"./pm25.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8u7Bxqi6bwF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weather = sc.textFile(\"./pm25.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aMVBdYNO6bwH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟2: 試試看是否成功上傳  (使用count( ), first( ), collect( ), take( ) )"
      ]
    },
    {
      "metadata": {
        "id": "QeiPKyGe6bwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ad6537eb-8898-4274-8049-8db7e457f76f"
      },
      "cell_type": "code",
      "source": [
        "print weather.count()\n",
        "print weather.first()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "465318\n",
            "日期,測站,測項,00,01,02,03,04,05,06,07,08,09,10,11,12,13,14,15,16,17,18,19,20,21,22,23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-6xuyI9R6bwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f3c05861-f325-4e2d-d6b3-fa29663aee5c"
      },
      "cell_type": "code",
      "source": [
        "lis = weather.take(5)\n",
        "for x in lis:\n",
        "  print x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "日期,測站,測項,00,01,02,03,04,05,06,07,08,09,10,11,12,13,14,15,16,17,18,19,20,21,22,23\n",
            "2015/01/01,龍潭,AMB_TEMP,14,14,14,13,13,13,12,12,13,14,14,14,14,14,13,13,12,11,11,11,11,11,11,11\n",
            "2015/01/01,龍潭,CO,0.69,0.72,0.69,0.64,0.54,0.47,0.45,0.48,0.51,0.54,0.54,0.5,0.47,0.38,0.36,0.35,0.34,0.37,0.34,0.29,0.26,0.22,0.19,0.18\n",
            "2015/01/01,龍潭,NO,0.3,0.1,0.6,2,2,1.9,2.2,3.1,3.7,4.3,4.3,4.5,3.3,4.1,3.1,3.6,3.6,2.8,2.8,2.5,2.2,1.4,2.1,2\n",
            "2015/01/01,龍潭,NO2,11,9.6,8.7,9.1,9.6,9.9,11,13,11,12,12,11,11,9.9,9.9,10,11,13,11,10,8.2,7.3,6.5,5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6lZMZ1m06bwO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 練習1: 讓我們求取2015年，大里每小時的平均pm25數值。\n",
        "## 注意事項：\n",
        "1. 資料分割：原始資料每一行為一個觀測值，我們必須將資料進行分割，才能逐一計算與進行操作。\n",
        "2. 資料清洗：在氣象局的原始資料裡，有些數值由於當初偵測時有異常，所以會加註特別符號如\\*\\#等特殊符號，這些數值我們必須先經過前處理，我們才能進行算術運算。\n",
        "3. 資料選擇：將大里資料挑選出來\n",
        "4. 產生key-value，也就是(小時,pm25值)\n",
        "5. 利用flatMap(), reduceByKey(), groupByKey()，將不同日期但相同時間的pm25值收集起來。\n",
        "6. 計算平均值, 標準差, 最大最小值。\n"
      ]
    },
    {
      "metadata": {
        "id": "A7aedWEz6bwO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟一：資料分割 (使用map () 與 split( ))"
      ]
    },
    {
      "metadata": {
        "id": "_DDuC6At6bwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3d37a8a3-f647-4d0d-b7d1-126294ffc3bb"
      },
      "cell_type": "code",
      "source": [
        "weatherParse = weather.map(lambda line : line.split(\",\"))\n",
        "r = weatherParse.take(5)\n",
        "\n",
        "for x in r:\n",
        "    for i in range(len(x)):\n",
        "        print x[i],\n",
        "    print \"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "日期 測站 測項 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \n",
            "2015/01/01 龍潭 AMB_TEMP 14 14 14 13 13 13 12 12 13 14 14 14 14 14 13 13 12 11 11 11 11 11 11 11 \n",
            "2015/01/01 龍潭 CO 0.69 0.72 0.69 0.64 0.54 0.47 0.45 0.48 0.51 0.54 0.54 0.5 0.47 0.38 0.36 0.35 0.34 0.37 0.34 0.29 0.26 0.22 0.19 0.18 \n",
            "2015/01/01 龍潭 NO 0.3 0.1 0.6 2 2 1.9 2.2 3.1 3.7 4.3 4.3 4.5 3.3 4.1 3.1 3.6 3.6 2.8 2.8 2.5 2.2 1.4 2.1 2 \n",
            "2015/01/01 龍潭 NO2 11 9.6 8.7 9.1 9.6 9.9 11 13 11 12 12 11 11 9.9 9.9 10 11 13 11 10 8.2 7.3 6.5 5.5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CB_BMIXf6bwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟二：將大里站資料從全部資料集中挑選出來 (filter)"
      ]
    },
    {
      "metadata": {
        "id": "P-np2VJz6bwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "須留意unicode與string的差別,  u'大里'"
      ]
    },
    {
      "metadata": {
        "id": "PwzyA92o6bwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "d6197142-6caa-4821-b867-49f7b1f31edf"
      },
      "cell_type": "code",
      "source": [
        "wea_dali = weatherParse.filter(lambda x: x[1] == u'大里' and x[2]== \"PM2.5\")\n",
        "lis = wea_dali.take(50)\n",
        "for x in lis:\n",
        "      for i in range(len(x)):\n",
        "          print x[i],\n",
        "      print \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2015/01/01 大里 PM2.5 53 55 58 53 43 36 35 42 55 64 65 59 52 44 47 41 43 40 42 35 28 20 18 16\n",
            "2015/01/02 大里 PM2.5 21 22 26 23 20 18 15 21 21 25 29 32 34 29 32 39 51 51 47 43 43 48 47 53\n",
            "2015/01/03 大里 PM2.5 48 48 43 38 37 36 37 34 37 46 64 77 83 75 68 69 64 65 59 66 71 66 57 48\n",
            "2015/01/04 大里 PM2.5 60 56 53 43 53 53 52 44 44 50 49 51 45 42 40 38 36 43 51 63 68 72 66 58\n",
            "2015/01/05 大里 PM2.5 48 42 42 34 34 28 34 35 45 47 54 46 35 19 16 21 24 28 37 52 60 62 64 61\n",
            "2015/01/06 大里 PM2.5 59 40 34 25 27 29 26 33 42 47 38 24 14 8 17 30 51 62 68 83 83 96 103 110\n",
            "2015/01/07 大里 PM2.5 117 110 97 68 47 39 34 27 22 15 14  23 18 16 12 10 6 5 9 15 21 23 15\n",
            "2015/01/08 大里 PM2.5 7 9 13 18 11 12 17 29 34 39 41 46 46 44 43 39 41 46 47 48 47 47 43 33\n",
            "2015/01/09 大里 PM2.5 35 34 37 30 25 25 22 21 18 20 14 12 21 31 44 46 52 44 39 37 43 43 42 39\n",
            "2015/01/10 大里 PM2.5 38 33 31 24 20 19 22 31 31 45 48 49 38 39 43 46 43 36 33 29 37 34 39 33\n",
            "2015/01/11 大里 PM2.5 37 41 43 43 27 22 26 34 39 37 51 53 61 56 48 43 37 43 43 48 54 51 46 35\n",
            "2015/01/12 大里 PM2.5 36 40 33 32 33 40 37 34 39 53 60 65 57 50 52 51 43 24 20 28 35 40 30 36\n",
            "2015/01/13 大里 PM2.5 36 36 32 33 38 45 38 45 45 76 84 96 92 87 64 33 21 22 20 15 7 12 9 11\n",
            "2015/01/14 大里 PM2.5 10 7 3 0 3 7 5 1 0 0 0 0 0 0 4 12 13 10 12 14 21 19 15 8\n",
            "2015/01/15 大里 PM2.5 2 3 7 3 7 5 10 7 13 16 14 8 5 13 20 30 30 33 28 29 33 26 23 12\n",
            "2015/01/16 大里 PM2.5 16 15 17 16 16 13 5 10 14 30 30 25 -4# 22 23 30 33 40 43 45 37 34 38 43\n",
            "2015/01/17 大里 PM2.5 42 33 25 18 13 9 12 20 28 33 33 43 52 55 57 60 66 77 76 76 77 74 82 75\n",
            "2015/01/18 大里 PM2.5 77 66 61 62 70 71 69 71 75 82 90 94 88 75 57 47 33 31 25 21 16 16 18 16\n",
            "2015/01/19 大里 PM2.5 14 14 19 18 16 7 6 12 18 30 26 28 31 32 35 37 41 43 42 50 53 54 57 62\n",
            "2015/01/20 大里 PM2.5 62 57 52 53 61 62 62 65 73 82 83 88 83 81 73 71 69 71 66 55 49 42 49 43\n",
            "2015/01/21 大里 PM2.5 46 37 30 31 31 38 42 46 46 36 33 33 37 34 33 33 34 39 48 50 47 45 43 39\n",
            "2015/01/22 大里 PM2.5 36 46 51 43 33 27 36 36 43 29 29 26 32 31 42  73 73 80 82 86 70 74 66\n",
            "2015/01/23 大里 PM2.5 61 47 46 55 49 39 29 31 29 19 12 14 30 49 57 55 57 56 64 72 73 75 68 68\n",
            "2015/01/24 大里 PM2.5 63 61 59 58 56 52 39 33 34 40 30 33 49 66 76 75 73 60 58 67 83 88 87 80\n",
            "2015/01/25 大里 PM2.5 71 68 65 63 63 62 57 55 65 70 79 75 75 64 59 68 78 86 80 74 66 60 49 44\n",
            "2015/01/26 大里 PM2.5 50 53 48 43 38 40 38 47 49 59 55 53 39 29 28 38 51 55 53 55 54 61 55 61\n",
            "2015/01/27 大里 PM2.5 56 52 41 46 49 52 43 43 48 48 40 30 30 33 36 37 35 36 43 46 42 30 22 17\n",
            "2015/01/28 大里 PM2.5 17 9 12 6 7 2 0 0 0 0 2 7 8 13 11 15 12 20 23 21 13 7 11 12\n",
            "2015/01/29 大里 PM2.5 14 14 12 7 1 0 4 6 12 16 15  52x 38x 30 29 27 29 24 24 21 19 19 23\n",
            "2015/01/30 大里 PM2.5 17 15 13 15 14 14 9 8 10 12 12 8 7 12 16 25 24 24 14 10 5 3 7 6\n",
            "2015/01/31 大里 PM2.5 6 0 1 9 9 10 7 12 12 10 17 23 26 27 28 33 31 35 30 33 23 16 8 8\n",
            "2015/02/01 大里 PM2.5 17 11 8 2 3 1 0 2 5 10 8 10 23 26 23 13 11 16 18 23 23 15 16 12\n",
            "2015/02/02 大里 PM2.5 15 12 18 25 25 25 25 32 37 39 45 47 49 45 36 30 21 24 23 27 24 19 10 15\n",
            "2015/02/03 大里 PM2.5 23 27 25 22 17 17 16 23 26 31 28 20 17 22 27 25 23 13 5 3 2 2 2 10\n",
            "2015/02/04 大里 PM2.5 10 12 9 12 7 4 4 2 13 20 26 16 10 19 23 26 21 26 33 28 29 27 31 26\n",
            "2015/02/05 大里 PM2.5 21 28 25 33 33 37 32 19 19 24 39 53 65   93 93 90 86 80 76 75 80 71\n",
            "2015/02/06 大里 PM2.5 63 53 52 51 51 47 43 30 27 28  41 56 60 59 53 53 51 44 41 39 41 35 31\n",
            "2015/02/07 大里 PM2.5 32 32 38 43 49 48 47 54 56 60 62 66 70 73 60 46 23 25 23 40 36 32 25 29\n",
            "2015/02/08 大里 PM2.5 39 38 34 28 14 15 13 23 18 24 26 32 31 33 36 39 38 49 53 60 53 43 34 28\n",
            "2015/02/09 大里 PM2.5 23 15 6 3 6 9 9 7 8 7 12 12 12 7 9 9 12 11 15 12 16 11 15 8\n",
            "2015/02/10 大里 PM2.5 9 3 7 3 4 0 0 0 3 12  11 20 22 28 26 30 32 24 14 17 19 29 24\n",
            "2015/02/11 大里 PM2.5 24 23 24 27 23 11 16 14 32 33 55 58 55 37 24 23 23 30 28 28 27 32 44 47\n",
            "2015/02/12 大里 PM2.5 54 48 47 43 42 43 43 55 54 53 51  48 45 39 45 48 47 47 44 49 56 64 61\n",
            "2015/02/13 大里 PM2.5 51 49 44 46 39 39 37 38 53 54 53 39 39 44 50 50 53 63 74 75 68 70 62 62\n",
            "2015/02/14 大里 PM2.5 54 57 53 52 58 57 53 53 74 82 81 72 68 73 58 53 35 40 48 50 59 57 67 68\n",
            "2015/02/15 大里 PM2.5 66 83 88 94 81 64 58 53 51 57 48 53 43 70 94 104 86 67 58 70 79 79 74 65\n",
            "2015/02/16 大里 PM2.5 70 67 63 55 39 28 28 46 67x 64x  41 33 21 24 18 18 16 23 27 27 38 41 44\n",
            "2015/02/17 大里 PM2.5 43 34 37 32 36 31 23 28 33 49 60 70 77 62 54 41 46 43 41 47 52 59 58 63\n",
            "2015/02/18 大里 PM2.5 67 71 70 67 59 55 51 53 53 55 49 41 38 44 51 53 53 57 49 50 48 47 47 42\n",
            "2015/02/19 大里 PM2.5 58 60 62 47 49 43 37 39 47 58 54 52 51 46 43 35 29 31 27 33 33 43 40 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ImDZp8136bwV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟三：資料清洗 (使用 map(), str.strip())\n",
        "#### 在氣象局的原始資料裡，有些數值由於當初偵測時有異常，所以會加註特別符號如\\*\\#等特殊符號，或者沒有取到數值為一空值，這些數值我們必須先經過前處理，我們才能進行算術運算。\n",
        "1. ```2015/01/29 大里 PM2.5 14 14 12 7 1 0 4 6 12 16 15  52x 38x 30 29 27 29 24 24 21 19 19 23```\n",
        "2. ```2015/01/16 大里 PM2.5 16 15 17 16 16 13 5 10 14 30 30 25 -4# 22 23 30 33 40 43 45 37 34 38 43``` "
      ]
    },
    {
      "metadata": {
        "id": "Uqf9UPnz6bwV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def strip_symbol(x):\n",
        "    for i in range(len(x)):\n",
        "        x[i] = x[i].strip(\"-*#x\") # remove non-digits\n",
        "        if x[i]==\"\": x[i]=\"0\"\n",
        "    return x\n",
        "\n",
        "wea_dali = wea_dali.map(strip_symbol)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vWnybfVB6bwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟四：key value pair的產生 (重要的操作概念)\n",
        "*將每小時資料轉成(小時,pm數值)，以求取每小時的平均值。\n",
        "\n",
        "例如：\n",
        "    2015/01/01 大里 PM2.5 53 55 58 53 43 36 35 42 55 64 65 59 52 44 47 41 43 40 42 35 28 20 18 16\n",
        "    --> [(3, 53) (4, 55) (5, 58) (6, 53) (7, 43) (8, 36) (9, 35) (10, 42) (11, 55) (12, 64) (13, 65) (14, 59) (15, 52) (16, 44) (17, 47) (18, 41) (19, 43) (20, 40) (21, 42) (22, 35) (23, 28) (24, 20) (25, 18) (26, 16)]\n"
      ]
    },
    {
      "metadata": {
        "id": "iGjDPGJl6bwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "312b8367-4285-428d-84ff-3a96fed9e05f"
      },
      "cell_type": "code",
      "source": [
        "for i in wea_dali.first():\n",
        "    print i,"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2015/01/01 大里 PM2.5 53 55 58 53 43 36 35 42 55 64 65 59 52 44 47 41 43 40 42 35 28 20 18 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OPJlnWbz6bwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8b523f6e-2bbb-4626-a3e6-c8dcf520b815"
      },
      "cell_type": "code",
      "source": [
        "def hourKeyGen(x):\n",
        "    hourkeypair = []\n",
        "    for i in range(3,27):\n",
        "        hourkeypair.append((i-3,float(x[i])))\n",
        "    return hourkeypair\n",
        "\n",
        "wea_dali_byHourkey = wea_dali.map(hourKeyGen)\n",
        "\n",
        "for i in wea_dali_byHourkey.first():\n",
        "    print i,"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 53.0) (1, 55.0) (2, 58.0) (3, 53.0) (4, 43.0) (5, 36.0) (6, 35.0) (7, 42.0) (8, 55.0) (9, 64.0) (10, 65.0) (11, 59.0) (12, 52.0) (13, 44.0) (14, 47.0) (15, 41.0) (16, 43.0) (17, 40.0) (18, 42.0) (19, 35.0) (20, 28.0) (21, 20.0) (22, 18.0) (23, 16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kNfl3Vio6bwd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟五： 利用flatMap(), reduceByKey(), groupByKey()，將不同日期但相同時間的pm25值收集起來。(使用flatMap)"
      ]
    },
    {
      "metadata": {
        "id": "rQWgeD-w6bwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "dec41453-97e5-479c-a719-722b99a09d51"
      },
      "cell_type": "code",
      "source": [
        "def hourKeyGen(x):\n",
        "    hourkeypair = []\n",
        "    for i in range(3,27):\n",
        "        hourkeypair.append((i-3,float(x[i])))\n",
        "    return hourkeypair\n",
        "\n",
        "byHourkey = wea_dali.flatMap(hourKeyGen)\n",
        "byHourkey.reduceByKey(lambda x,y: x+y).take(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 9838.0),\n",
              " (2, 9229.0),\n",
              " (4, 8346.0),\n",
              " (6, 8121.0),\n",
              " (8, 9580.0),\n",
              " (10, 10919.0),\n",
              " (12, 11505.0),\n",
              " (14, 10172.0),\n",
              " (16, 10396.0),\n",
              " (18, 10396.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "dtQpIRWJ6bwh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟六： 計算大里區每個小時區間中，平均之pm25數值 (使用reduceByKey)"
      ]
    },
    {
      "metadata": {
        "id": "SlXpUgc36bwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "cd1934b1-d030-4d2a-886b-667bdfa532c8"
      },
      "cell_type": "code",
      "source": [
        "avg_pm25_hour = byHourkey.reduceByKey(lambda x,y: x+y)\n",
        "avg_pm25_hour.map(lambda x:(x[0],x[1]/365)).collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 26.953424657534246),\n",
              " (2, 25.284931506849315),\n",
              " (4, 22.865753424657534),\n",
              " (6, 22.24931506849315),\n",
              " (8, 26.246575342465754),\n",
              " (10, 29.915068493150685),\n",
              " (12, 31.52054794520548),\n",
              " (14, 27.86849315068493),\n",
              " (16, 28.482191780821918),\n",
              " (18, 28.482191780821918),\n",
              " (20, 30.136986301369863),\n",
              " (22, 29.161643835616438),\n",
              " (1, 25.704109589041096),\n",
              " (3, 23.76164383561644),\n",
              " (5, 21.975342465753425),\n",
              " (7, 23.572602739726026),\n",
              " (9, 29.252054794520546),\n",
              " (11, 30.265753424657536),\n",
              " (13, 30.65205479452055),\n",
              " (15, 28.147945205479452),\n",
              " (17, 28.295890410958904),\n",
              " (19, 29.315068493150687),\n",
              " (21, 29.783561643835615),\n",
              " (23, 27.852054794520548)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "Mko2dCdz6bwk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟七： 根據pm25平均濃度，進行排序。使用top( )"
      ]
    },
    {
      "metadata": {
        "id": "_qgZSxDs6bwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "455df82a-0801-4c48-e3a0-cc45f6d7a744"
      },
      "cell_type": "code",
      "source": [
        "avg_pm25_hour = byHourkey.reduceByKey(lambda x,y: x+y)\n",
        "avg_pm25_hour.map(lambda x:(x[0],x[1]/365.0)).map(lambda x: (x[1],x[0])).top(24)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(31.52054794520548, 12),\n",
              " (30.65205479452055, 13),\n",
              " (30.265753424657536, 11),\n",
              " (30.136986301369863, 20),\n",
              " (29.915068493150685, 10),\n",
              " (29.783561643835615, 21),\n",
              " (29.315068493150687, 19),\n",
              " (29.252054794520546, 9),\n",
              " (29.161643835616438, 22),\n",
              " (28.482191780821918, 18),\n",
              " (28.482191780821918, 16),\n",
              " (28.295890410958904, 17),\n",
              " (28.147945205479452, 15),\n",
              " (27.86849315068493, 14),\n",
              " (27.852054794520548, 23),\n",
              " (26.953424657534246, 0),\n",
              " (26.246575342465754, 8),\n",
              " (25.704109589041096, 1),\n",
              " (25.284931506849315, 2),\n",
              " (23.76164383561644, 3),\n",
              " (23.572602739726026, 7),\n",
              " (22.865753424657534, 4),\n",
              " (22.24931506849315, 6),\n",
              " (21.975342465753425, 5)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "sReXkMgl6bwo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 步驟八： 計算每個時間點的統計值，例如最大值、最小值、平均值、標準差(使用 groupByKey()與mapValues())"
      ]
    },
    {
      "metadata": {
        "id": "1hYPP0FB6bwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "19f173a8-6238-44bf-af63-99f865d8f46e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def hourKeyGen(x):\n",
        "    hourkeypair = []\n",
        "    for i in range(3,27):\n",
        "        hourkeypair.append((i-3,float(x[i])))\n",
        "    return hourkeypair\n",
        "\n",
        "hour_stat_list = byHourkey.groupByKey().mapValues(list).collect()\n",
        "\n",
        "for i in sorted(hour_stat_list):\n",
        "    print i[0],max(i[1]),min(i[1]),np.mean(i[1]),np.var(i[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 117.0 0.0 26.953424657534246 382.0224882717208\n",
            "1 110.0 0.0 25.704109589041096 362.93710639894914\n",
            "2 107.0 0.0 25.284931506849315 354.74621129667855\n",
            "3 102.0 0.0 23.76164383561644 330.0555151060236\n",
            "4 98.0 0.0 22.865753424657534 310.53814224057044\n",
            "5 88.0 0.0 21.975342465753425 299.8651454306624\n",
            "6 96.0 0.0 22.24931506849315 273.9624995308688\n",
            "7 102.0 0.0 23.572602739726026 286.573495965472\n",
            "8 109.0 0.0 26.246575342465754 311.0241321073372\n",
            "9 114.0 0.0 29.252054794520546 361.73920810658655\n",
            "10 114.0 0.0 29.915068493150685 394.8064852692814\n",
            "11 117.0 0.0 30.265753424657536 407.89375867892664\n",
            "12 112.0 0.0 31.52054794520548 404.74820791893416\n",
            "13 103.0 0.0 30.65205479452055 385.36112591480577\n",
            "14 94.0 0.0 27.86849315068493 346.4484593732408\n",
            "15 104.0 0.0 28.147945205479452 354.9753724901482\n",
            "16 93.0 0.0 28.482191780821918 297.4003677988365\n",
            "17 90.0 0.0 28.295890410958904 303.5343666729217\n",
            "18 88.0 0.0 28.482191780821918 299.4825595796585\n",
            "19 99.0 0.0 29.315068493150687 342.48429348845934\n",
            "20 101.0 0.0 30.136986301369863 365.7127416025521\n",
            "21 100.0 0.0 29.783561643835615 375.3093188215425\n",
            "22 107.0 0.0 29.161643835616438 390.53003565396887\n",
            "23 110.0 0.0 27.852054794520548 368.1315368737099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AF0Vd9yZ6bwq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 練習2: 請求取2015年，全國pm2.5最高的前十個工作站測點以及其日期。"
      ]
    },
    {
      "metadata": {
        "id": "cJBYpK6G6bws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### weatherParse 為原始資料集\n",
        "pm25_data_set = weatherParse.filter(lambda x: x[2]==\"PM2.5\")\n",
        "\n",
        "### 資料清洗\n",
        "def strip_symbol(x):\n",
        "    for i in range(len(x)):\n",
        "        #x[i] = x[i].strip(\"-*#x\") # remove non-digits\n",
        "        if \"#\" in x[i]:x[i]=\"0\"\n",
        "        if \"*\" in x[i]:x[i]=\"0\"\n",
        "        if \"x\" in x[i]:x[i]=\"0\"\n",
        "        if \"-\" in x[i]:x[i]=\"0\"\n",
        "        if x[i]==\"\": x[i]=\"0\"\n",
        "    return x\n",
        "\n",
        "clean_pm25_data_set = pm25_data_set.map(strip_symbol)\n",
        "#clean_pm25_data_set.take(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4sEW-ZIo6bww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "30b596c1-a350-4f7d-9ddd-857f9abbdf2a"
      },
      "cell_type": "code",
      "source": [
        "def date_location_time (x):\n",
        "    date_loc_time_measure = []\n",
        "    for i in range(3,27):\n",
        "        date_loc_time_string = x[0]+\"@\"+x[1]+\":\"+str(i-3)+u'點'\n",
        "        date_loc_time_measure.append((date_loc_time_string, int(x[i])))\n",
        "    return date_loc_time_measure\n",
        "\n",
        "top10pm25 = clean_pm25_data_set.flatMap(date_location_time).map(lambda x: (x[1],x[0])).top(10)    \n",
        "\n",
        "for i in top10pm25:\n",
        "    print i[0],i[1],\n",
        "    print \"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "319 2015/04/18@埔里:21點 \n",
            "301 2015/01/01@馬公:1點 \n",
            "296 2015/01/01@馬公:0點 \n",
            "238 2015/04/18@埔里:22點 \n",
            "238 2015/01/06@金門:11點 \n",
            "213 2015/01/06@金門:10點 \n",
            "196 2015/05/11@朴子:21點 \n",
            "196 2015/01/03@三義:22點 \n",
            "193 2015/05/11@朴子:20點 \n",
            "189 2015/01/06@金門:9點 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z3Ahgkm-6bwy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "precTop10=[]\n",
        "stationsTop10=[]\n",
        "for result in top10pm25:\n",
        "    precTop10.append(result[0])\n",
        "    stationsTop10.append(result[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAYJncl_6bwz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plot your results."
      ]
    },
    {
      "metadata": {
        "id": "JuqkVh376bwz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 10\n",
        "index = np.arange(N)  \n",
        "bar_width = 0.5\n",
        "\n",
        "plt.bar(index, precTop10, bar_width,\n",
        "                 color='b')\n",
        "plt.xlabel('Stations')\n",
        "plt.ylabel('pm25')\n",
        "plt.title('10 stations with the highest average pm25')\n",
        "plt.xticks(index + bar_width, stationsTop10, rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWayHXWE6bw2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 練習3: 請算算看2015全國哪個測站，紫爆天數最多？\n",
        "### 假設當日平均值大於60，則算該日該地區紫爆\n"
      ]
    },
    {
      "metadata": {
        "id": "Liq1IcEX6bw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1126
        },
        "outputId": "fa69d879-ded5-4e83-8c78-30fb8cb1557f"
      },
      "cell_type": "code",
      "source": [
        "pm25_data_set = weatherParse.filter(lambda x: x[2]==\"PM2.5\")\n",
        "\n",
        "### 資料清洗\n",
        "def strip_symbol(x):\n",
        "    for i in range(len(x)):\n",
        "        #x[i] = x[i].strip(\"-*#x\") # remove non-digits\n",
        "        if \"#\" in x[i]:x[i]=\"0\"\n",
        "        if \"*\" in x[i]:x[i]=\"0\"\n",
        "        if \"x\" in x[i]:x[i]=\"0\"\n",
        "        if \"-\" in x[i]:x[i]=\"0\"\n",
        "        if x[i]==\"\": x[i]=\"0\"\n",
        "    return x\n",
        "\n",
        "def toFloat(x):\n",
        "    location = x[1]\n",
        "    del x[0:3]\n",
        "    for i in range(len(x)):\n",
        "        x[i]=float(x[i])\n",
        "    return (location, sum(x)/len(x))\n",
        "\n",
        "clean_pm25_data_set = pm25_data_set.map(strip_symbol)\n",
        "Worst = clean_pm25_data_set.map(toFloat).filter(lambda x:x[1]>60).groupByKey().mapValues(list)\\\n",
        ".map(lambda x:(x[0],len(x[1]))).sortBy(lambda x:x[1], ascending=False).collect()\n",
        "\n",
        "for loc in Worst:\n",
        "    print loc[0],loc[1],\n",
        "    print \"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "竹山 28 \n",
            "斗六 28 \n",
            "崙背 25 \n",
            "金門 21 \n",
            "善化 20 \n",
            "埔里 18 \n",
            "復興 17 \n",
            "左營 17 \n",
            "橋頭 16 \n",
            "小港 15 \n",
            "嘉義 14 \n",
            "楠梓 13 \n",
            "麥寮 13 \n",
            "大里 13 \n",
            "二林 13 \n",
            "忠明 12 \n",
            "鳳山 12 \n",
            "大寮 12 \n",
            "仁武 12 \n",
            "臺西 11 \n",
            "西屯 10 \n",
            "馬祖 10 \n",
            "前鎮 10 \n",
            "林園 10 \n",
            "安南 9 \n",
            "屏東 9 \n",
            "臺南 9 \n",
            "新營 9 \n",
            "潮州 8 \n",
            "南投 8 \n",
            "前金 8 \n",
            "新港 8 \n",
            "彰化 7 \n",
            "線西 7 \n",
            "朴子 6 \n",
            "新莊 4 \n",
            "頭份 4 \n",
            "沙鹿 4 \n",
            "桃園 4 \n",
            "萬華 4 \n",
            "中山 3 \n",
            "苗栗 3 \n",
            "林口 3 \n",
            "古亭 3 \n",
            "美濃 3 \n",
            "龍潭 2 \n",
            "永和 2 \n",
            "竹東 2 \n",
            "三重 2 \n",
            "基隆 2 \n",
            "新店 2 \n",
            "松山 2 \n",
            "平鎮 2 \n",
            "士林 1 \n",
            "萬里 1 \n",
            "板橋 1 \n",
            "新竹 1 \n",
            "大園 1 \n",
            "觀音 1 \n",
            "中壢 1 \n",
            "土城 1 \n",
            "湖口 1 \n",
            "豐原 1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-4izkMXe6bw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}